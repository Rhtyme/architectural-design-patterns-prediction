{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f3WhOg8Gpw8M"
   },
   "source": [
    "# Machine learning based apprpoach for achitecture detection from GitHub repositories [Coach Dataset]\n",
    "\n",
    "```\n",
    "Author: Gcinizwe Dlamini\n",
    "```\n",
    "<hr>\n",
    "\n",
    "```\n",
    "The notebook is dedicated to data extraction, EDA and classisification\n",
    "\n",
    "Main libraries used :     \n",
    "- catboost\n",
    "- pandas\n",
    "- sklearn\n",
    "- interpret\n",
    "```\n",
    "\n",
    "If catboost not installed run  `!pip install catboost`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hfcCdsZLqgwx"
   },
   "source": [
    "## Extract data from files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "MGCMhA6fqF4a"
   },
   "outputs": [],
   "source": [
    "import os, glob\n",
    "import pandas as pd\n",
    "import numpy as np \n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "fH9neRRcrPza"
   },
   "outputs": [],
   "source": [
    "def get_data_from_csv(train_path='../Data/coach_data.csv', print_stat=False):\n",
    "    full_data = pd.read_csv(train_path)\n",
    "\n",
    "    if print_stat:\n",
    "        pass\n",
    "    return full_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MVC': 0, 'MVP': 1, 'MVVM': 2, 'NONE': 3}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data  = get_data_from_csv()\n",
    "vals = np.unique(full_data.label).tolist()\n",
    "mapping_labels = dict(zip(vals,np.arange(len(vals)))) \n",
    "mapping_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_data['label'] = full_data['label'].apply(lambda x : mapping_labels.get(x) )\n",
    "\n",
    "Xtrain, ytrain = full_data.drop('label',axis=1).values, full_data.label.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JCAHTUDQV2j5"
   },
   "source": [
    "## Define, train and Evaluate ML models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "j2T2fPdvVX5K"
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from interpret.glassbox import ExplainableBoostingClassifier\n",
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VKSojA5DAsMb",
    "outputId": "b7c1988b-a4f2-4d99-ba7c-14203762b5dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.496 F1 with a standard deviation of 0.18 \n",
      "\n",
      "0.582 F1 with a standard deviation of 0.11 \n",
      "\n",
      "0.544 F1 with a standard deviation of 0.04 \n",
      "\n",
      "0.575 F1 with a standard deviation of 0.14 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Cross Validation \n",
    "dt = DecisionTreeClassifier()\n",
    "scores = cross_val_score(dt, Xtrain, ytrain, cv=5, scoring='f1_weighted')\n",
    "print(\"%0.3f F1 with a standard deviation of %0.2f \\n\" % (scores.mean(), scores.std()))\n",
    "\n",
    "\n",
    "## Cross Validation \n",
    "rf = RandomForestClassifier()\n",
    "scores = cross_val_score(rf, Xtrain, ytrain, cv=5, scoring='f1_weighted')\n",
    "print(\"%0.3f F1 with a standard deviation of %0.2f \\n\" % (scores.mean(), scores.std()))\n",
    "\n",
    "\n",
    "## Cross Validation CatBoost Classifier\n",
    "cb = CatBoostClassifier(verbose=False)\n",
    "scores = cross_val_score(cb, Xtrain, ytrain, cv=5, scoring='f1_weighted')\n",
    "print(\"%0.3f F1 with a standard deviation of %0.2f \\n\" % (scores.mean(), scores.std()))\n",
    "\n",
    "\n",
    "## Cross Validation \n",
    "ebm = ExplainableBoostingClassifier(random_state=1)\n",
    "scores = cross_val_score(ebm, Xtrain, ytrain, cv=5, scoring='f1_weighted')\n",
    "print(\"%0.3f F1 with a standard deviation of %0.2f \\n\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FZcUfU81VsZQ",
    "outputId": "1d6f40de-db17-4ade-b600-14bdb8c33378"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.539 F1 with a standard deviation of 0.18 \n",
      "\n",
      "neural network\n",
      "0.338 F1 with a standard deviation of 0.11 \n",
      "\n",
      "KNN\n",
      "0.583 F1 with a standard deviation of 0.11 \n",
      "\n",
      "SVM\n",
      "0.523 F1 with a standard deviation of 0.08 \n",
      "\n",
      "GaussianNB\n",
      "0.512 F1 with a standard deviation of 0.15 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(Xtrain)\n",
    "\n",
    "\n",
    "## Cross Validation LR\n",
    "clf = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "scores = cross_val_score(clf, Xtrain, ytrain, cv=5, scoring='f1_weighted')\n",
    "print(\"%0.3f F1 with a standard deviation of %0.2f \\n\" % (scores.mean(), scores.std()))\n",
    "\n",
    "\n",
    "print(\"neural network\")\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "## Cross Validation nn\n",
    "nn_clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf = make_pipeline(StandardScaler(), nn_clf)\n",
    "scores = cross_val_score(clf, Xtrain, ytrain, cv=5, scoring='f1_weighted')\n",
    "print(\"%0.3f F1 with a standard deviation of %0.2f \\n\" % (scores.mean(), scores.std()))\n",
    "\n",
    "\n",
    "print(\"KNN\")\n",
    "## Cross Validation \n",
    "clf = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
    "scores = cross_val_score(clf, Xtrain, ytrain, cv=5, scoring='f1_weighted')\n",
    "print(\"%0.3f F1 with a standard deviation of %0.2f \\n\" % (scores.mean(), scores.std()))\n",
    "\n",
    "print(\"SVM\")\n",
    "## Cross Validation SVM\n",
    "clf = make_pipeline(StandardScaler(), SVC())\n",
    "scores = cross_val_score(clf, Xtrain, ytrain, cv=5, scoring='f1_weighted')\n",
    "print(\"%0.3f F1 with a standard deviation of %0.2f \\n\" % (scores.mean(), scores.std()))\n",
    "\n",
    "print(\"GaussianNB\")\n",
    "## Cross Validation NB\n",
    "clf = make_pipeline(StandardScaler(), GaussianNB())\n",
    "scores = cross_val_score(clf, Xtrain, ytrain, cv=5, scoring='f1_weighted')\n",
    "print(\"%0.3f F1 with a standard deviation of %0.2f \\n\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Coach + our approah"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_csv(train_path='../Data/train.csv', test_path='../Data/test.csv', print_stat=False):\n",
    "    train_df = pd.read_csv(train_path)\n",
    "    test_df = pd.read_csv(test_path)\n",
    "\n",
    "    if print_stat:\n",
    "        pass\n",
    "    return train_df, test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MVC': 0, 'MVP': 1, 'MVVM': 2, 'NONE': 3}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mapping_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = full_data.query('label == @mapping_labels.get(\"MVP\") or label == @mapping_labels.get(\"MVVM\")')\n",
    "\n",
    "mapping_labels2 = {2:'mvp', 1: 'mvvm'}\n",
    "test_data['label'] = test_data['label'].apply(lambda x : mapping_labels2.get(x))\n",
    "\n",
    "mapping_labels3 = {\"mvp\":0,\"mvvm\":1}\n",
    "test_data['label'] = test_data['label'].apply(lambda x : mapping_labels3.get(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21, 83)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_data.query('label == @mapping_labels.get(\"MVP\") or label == @mapping_labels.get(\"MVVM\")').shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, test_df = get_data_from_csv()\n",
    "mapping_labels3 = {\"mvp\":0,\"mvvm\":1}\n",
    "\n",
    "train_df['label'] = train_df.label.apply(lambda x : mapping_labels3.get(x))\n",
    "test_df['label'] = test_df.label.apply(lambda x : mapping_labels3.get(x))\n",
    "\n",
    "\n",
    "Xtrain, ytrain = train_df.drop('label',axis=1).values, train_df.label.values\n",
    "Xtest, ytest = test_df.drop('label',axis=1).values, test_df.label.values\n",
    "\n",
    "Xtrain = np.vstack([Xtrain,Xtest])\n",
    "ytrain = np.hstack([ytrain,ytest])\n",
    "\n",
    "Xtest, ytest = test_data.drop('label',axis=1).values, test_data.label.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.67      0.67         9\n",
      "           1       0.75      0.75      0.75        12\n",
      "\n",
      "    accuracy                           0.71        21\n",
      "   macro avg       0.71      0.71      0.71        21\n",
      "weighted avg       0.71      0.71      0.71        21\n",
      "\n",
      "0.702 F1 with a standard deviation of 0.01 \n",
      "\n",
      "RandomForestClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89         9\n",
      "           1       0.92      0.92      0.92        12\n",
      "\n",
      "    accuracy                           0.90        21\n",
      "   macro avg       0.90      0.90      0.90        21\n",
      "weighted avg       0.90      0.90      0.90        21\n",
      "\n",
      "0.801 F1 with a standard deviation of 0.01 \n",
      "\n",
      "CatBoostClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00         9\n",
      "           1       1.00      1.00      1.00        12\n",
      "\n",
      "    accuracy                           1.00        21\n",
      "   macro avg       1.00      1.00      1.00        21\n",
      "weighted avg       1.00      1.00      1.00        21\n",
      "\n",
      "0.822 F1 with a standard deviation of 0.01 \n",
      "\n",
      "ExplainableBoostingClassifier\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.78      0.78         9\n",
      "           1       0.83      0.83      0.83        12\n",
      "\n",
      "    accuracy                           0.81        21\n",
      "   macro avg       0.81      0.81      0.81        21\n",
      "weighted avg       0.81      0.81      0.81        21\n",
      "\n",
      "0.813 F1 with a standard deviation of 0.01 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"DecisionTreeClassifier\")\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(Xtrain, ytrain)\n",
    "ypred = dt.predict(Xtest)\n",
    "print(classification_report(ytest, ypred))\n",
    "\n",
    "## Cross Validation \n",
    "dt = DecisionTreeClassifier()\n",
    "scores = cross_val_score(dt, Xtrain, ytrain, cv=5, scoring='f1_weighted')\n",
    "print(\"%0.3f F1 with a standard deviation of %0.2f \\n\" % (scores.mean(), scores.std()))\n",
    "\n",
    "\n",
    "print(\"RandomForestClassifier\")\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(Xtrain, ytrain)\n",
    "ypred = rf.predict(Xtest)\n",
    "print(classification_report(ytest, ypred))\n",
    "\n",
    "# feature importance from Random Forest\n",
    "rf_feature_importance = pd.DataFrame({'feature_importance_rf': rf.feature_importances_, \n",
    "                                      'feature_names': train_df.columns[:-1]}).sort_values(by=['feature_importance_rf'], \n",
    "                                        ascending=False)\n",
    "\n",
    "## Cross Validation \n",
    "rf = RandomForestClassifier()\n",
    "scores = cross_val_score(rf, Xtrain, ytrain, cv=5, scoring='f1_weighted')\n",
    "print(\"%0.3f F1 with a standard deviation of %0.2f \\n\" % (scores.mean(), scores.std()))\n",
    "\n",
    "print(\"CatBoostClassifier\")\n",
    "cb = CatBoostClassifier(verbose=False)\n",
    "cb.fit(Xtrain, ytrain)\n",
    "ypred = cb.predict(Xtest)\n",
    "print(classification_report(ytest, ypred))\n",
    "\n",
    "# feature importance from CatBoost Classifier\n",
    "feature_importance = pd.DataFrame({'feature_importance_cb': cb.feature_importances_, \n",
    "                                      'feature_names': train_df.columns[:-1]}).sort_values(by=['feature_importance_cb'], \n",
    "                                        ascending=False)\n",
    "\n",
    "## Cross Validation CatBoost Classifier\n",
    "cb = CatBoostClassifier(verbose=False)\n",
    "scores = cross_val_score(cb, Xtrain, ytrain, cv=5, scoring='f1_weighted')\n",
    "print(\"%0.3f F1 with a standard deviation of %0.2f \\n\" % (scores.mean(), scores.std()))\n",
    "\n",
    "print(\"ExplainableBoostingClassifier\")\n",
    "ebm = ExplainableBoostingClassifier(random_state=1)\n",
    "ebm.fit(train_df.drop('label',axis=1), train_df['label'].values)\n",
    "pred = ebm.predict(Xtest)\n",
    "print(classification_report(ytest, pred))\n",
    "\n",
    "# feature importance from Explainable Boosting Classifier\n",
    "ebm_feature_importance = pd.DataFrame({'feature_importance_ebm': ebm.feature_importances_, \n",
    "                                      'feature_names': ebm.feature_names}).sort_values(by=['feature_importance_ebm'], \n",
    "                                        ascending=False)\n",
    "\n",
    "## Cross Validation \n",
    "ebm = ExplainableBoostingClassifier(random_state=1)\n",
    "scores = cross_val_score(ebm, Xtrain, ytrain, cv=5, scoring='f1_weighted')\n",
    "print(\"%0.3f F1 with a standard deviation of %0.2f \\n\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.89      0.84         9\n",
      "           1       0.91      0.83      0.87        12\n",
      "\n",
      "    accuracy                           0.86        21\n",
      "   macro avg       0.85      0.86      0.86        21\n",
      "weighted avg       0.86      0.86      0.86        21\n",
      "\n",
      "0.819 F1 with a standard deviation of 0.01 \n",
      "\n",
      "neural network\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94         9\n",
      "           1       0.92      1.00      0.96        12\n",
      "\n",
      "    accuracy                           0.95        21\n",
      "   macro avg       0.96      0.94      0.95        21\n",
      "weighted avg       0.96      0.95      0.95        21\n",
      "\n",
      "0.815 F1 with a standard deviation of 0.00 \n",
      "\n",
      "KNN\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.78      0.82         9\n",
      "           1       0.85      0.92      0.88        12\n",
      "\n",
      "    accuracy                           0.86        21\n",
      "   macro avg       0.86      0.85      0.85        21\n",
      "weighted avg       0.86      0.86      0.86        21\n",
      "\n",
      "0.785 F1 with a standard deviation of 0.01 \n",
      "\n",
      "SVM\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      1.00      0.95         9\n",
      "           1       1.00      0.92      0.96        12\n",
      "\n",
      "    accuracy                           0.95        21\n",
      "   macro avg       0.95      0.96      0.95        21\n",
      "weighted avg       0.96      0.95      0.95        21\n",
      "\n",
      "0.822 F1 with a standard deviation of 0.01 \n",
      "\n",
      "GaussianNB\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.33      0.11      0.17         9\n",
      "           1       0.56      0.83      0.67        12\n",
      "\n",
      "    accuracy                           0.52        21\n",
      "   macro avg       0.44      0.47      0.42        21\n",
      "weighted avg       0.46      0.52      0.45        21\n",
      "\n",
      "0.517 F1 with a standard deviation of 0.03 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "scaler = StandardScaler()\n",
    "X_train_std = scaler.fit_transform(Xtrain)\n",
    "X_test_std = scaler.transform(Xtest)\n",
    "\n",
    "print(\"LogisticRegression\")\n",
    "lr = LogisticRegression()\n",
    "lr.fit(X_train_std, ytrain)\n",
    "ypred = lr.predict(X_test_std)\n",
    "print(classification_report(ytest, ypred))\n",
    "\n",
    "## Cross Validation LR\n",
    "clf = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "scores = cross_val_score(clf, Xtrain, ytrain, cv=5, scoring='f1_weighted')\n",
    "print(\"%0.3f F1 with a standard deviation of %0.2f \\n\" % (scores.mean(), scores.std()))\n",
    "\n",
    "\n",
    "print(\"neural network\")\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "nn_clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                hidden_layer_sizes=(5, 2), random_state=1)\n",
    "\n",
    "nn_clf.fit(X_train_std, ytrain)\n",
    "ypred = nn_clf.predict(X_test_std)\n",
    "print(classification_report(ytest, ypred))\n",
    "\n",
    "## Cross Validation nn\n",
    "nn_clf = MLPClassifier(solver='lbfgs', alpha=1e-5,\n",
    "                hidden_layer_sizes=(5, 2), random_state=1)\n",
    "clf = make_pipeline(StandardScaler(), nn_clf)\n",
    "scores = cross_val_score(clf, Xtrain, ytrain, cv=5, scoring='f1_weighted')\n",
    "print(\"%0.3f F1 with a standard deviation of %0.2f \\n\" % (scores.mean(), scores.std()))\n",
    "\n",
    "\n",
    "print(\"KNN\")\n",
    "knn = KNeighborsClassifier()\n",
    "knn.fit(X_train_std, ytrain)\n",
    "ypred = knn.predict(X_test_std)\n",
    "print(classification_report(ytest, ypred))\n",
    "\n",
    "## Cross Validation \n",
    "clf = make_pipeline(StandardScaler(), KNeighborsClassifier())\n",
    "scores = cross_val_score(clf, Xtrain, ytrain, cv=5, scoring='f1_weighted')\n",
    "print(\"%0.3f F1 with a standard deviation of %0.2f \\n\" % (scores.mean(), scores.std()))\n",
    "\n",
    "print(\"SVM\")\n",
    "svmclf = SVC()\n",
    "svmclf.fit(X_train_std, ytrain)\n",
    "ypred = svmclf.predict(X_test_std)\n",
    "print(classification_report(ytest, ypred))\n",
    "\n",
    "## Cross Validation SVM\n",
    "clf = make_pipeline(StandardScaler(), SVC())\n",
    "scores = cross_val_score(clf, Xtrain, ytrain, cv=5, scoring='f1_weighted')\n",
    "print(\"%0.3f F1 with a standard deviation of %0.2f \\n\" % (scores.mean(), scores.std()))\n",
    "\n",
    "print(\"GaussianNB\")\n",
    "gnb = GaussianNB()\n",
    "y_pred = gnb.fit(X_train_std, ytrain).predict(X_test_std)\n",
    "print(classification_report(ytest, y_pred))\n",
    "\n",
    "## Cross Validation NB\n",
    "clf = make_pipeline(StandardScaler(), GaussianNB())\n",
    "scores = cross_val_score(clf, Xtrain, ytrain, cv=5, scoring='f1_weighted')\n",
    "print(\"%0.3f F1 with a standard deviation of %0.2f \\n\" % (scores.mean(), scores.std()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "architectural design patterns.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
